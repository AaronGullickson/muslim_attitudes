---
title: "Testing Reliability and Validity of Constructed Variables"
output: 
  html_document: 
    toc: yes
    toc_depth: 4
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning = FALSE, error=FALSE)
library(here)
source(here("analysis","check_packages.R"))
load(here("analysis","output","pewdata_combined.RData"))
rotation_choice <- "oblimin"
```

## Introduction

This document will describe the candidate constructs that we considered creating for purposes of data reduction and model simplification. Each section will describe a specific construct and what variables we initially considered as candidates for loading into the construct. We then consider several rather complicated issues that need to be addressed when considering the creation of constructs in a cross-national context.

We first analyzed the reliability and validity of each construct at the global level, without consideration for particular countries. We estimated alpha parameters to test reliability and then conducted an exploratory factor analysis (EFA) to ensure that a single factor fit was satisfactory. The construction of alpha and the EFA were estimated based on tetrachoric/polychoric correlations between variablers rather than Pearson corrrelations to adjust for the categorical nature of all the variables under consideration here. This initial global analysis helped us refine the list of variables that might make up the construct.

The next step of the analysis was to investigate potential invariance across countries. Ideally, our construct should not just fit well across all countries but within each and every country. However, addressing this issue of measurement invariance is complex and evolving in the literature, both in terms of how to test for invariance and what to do in the face of invariance. Much of the literature uses multigroup confirmatory factor analysis to test for configural, metric, and scalar equivalence. An alternative and arguably better approach is to use item response theory (IRT). Given the categorical nature of the variables we consider, IRT is a more suitable approach, so we apply the techniques of Tay et. al. (2015) to test for invariance.


## Support for violent practices
<a href="#top">Back to top</a>

Here we want to capture whether respondents favor harsh and violent responses to violations of the social fabric/religious norms.  We considered the following variables for this construct:

+------------------------+---------------------------------------+---------------------------+
| Name                   | Question                              | Missing Countries         |
+========================+=======================================+===========================+
| death_apostasy (Q92b)  |Favor the death penalty for people who | - Iran                    |
|                        |leave the Muslim religion              | - Morocco                 |
|                        |                                       | - Uzbekistan              |
+------------------------+---------------------------------------+---------------------------+
| severe_corporal (Q92c) |Favor punishments like whipping or     | - Iran                    |
|                        |cutting off hands for crimes like theft| - Morocco                 |
|                        |and robbery.                           | - Uzbekistan              |
+------------------------+---------------------------------------+---------------------------+
| stone_adultery (Q92d)  |Favor stoning people who commit        | - Iran                    |
|                        |adultery.                              | - Morocco                 |
|                        |                                       | - Uzbekistan              |
+------------------------+---------------------------------------+---------------------------+
| civilian_targets (Q89) | Violence against civilian targets in  | - Iran                    |
|                        | defense of Islam justified.           | - Thailand                |
|                        | I don't think this really goes        | - Uzbekistan              |
|                        | here but may want to consider it      | - Lebanon                 |
|                        | separately.                           |                           |
+------------------------+---------------------------------------+---------------------------+

There are also question about the justifiability of honor killings for sexual impropriety (separately for men and women), but these variables is missing for the majority of countries and se do not consider them here. 

First, we look at the correlations, alpha, and factor loadings across all respondents, regardless of country.

```{r violent_practices}
violent <- cbind(death_apostasy=as.numeric(pew$death_apostasy),
                 severe_corporal=as.numeric(pew$severe_corporal),
                 stone_adultery=as.numeric(pew$stone_adultery),
                 civilian_target=as.numeric(pew$civilian_target))
corrgram(violent, upper.panel="panel.cor", order="PCA")

psych::alpha(cor(violent, use="pairwise.complete.obs"))

loadings(fa(cor(violent, use="pairwise.complete.obs"),1,rotate=rotation_choice))
fa.diagram(fa(cor(violent, use="pairwise.complete.obs"),1,rotate=rotation_choice))
loadings(fa(cor(violent, use="pairwise.complete.obs"),2,rotate=rotation_choice))
fa.diagram(fa(cor(violent, use="pairwise.complete.obs"),2,rotate=rotation_choice))
loadings(fa(cor(violent, use="pairwise.complete.obs"),3,rotate=rotation_choice))
fa.diagram(fa(cor(violent, use="pairwise.complete.obs"),3,rotate=rotation_choice))
```

The results here all suggest strong reliability and a single factor for the first three items and that the targeting of civilians question does not fit as well. Therefore, we removed the last item. which led to a good fit and a clear preference for a single factor.

```{r}
#without civilian targets
violent <- violent[,-4]
psych::alpha(cor(violent, use="pairwise.complete.obs"))
vss(cor(violent, use="pairwise.complete.obs"))
loadings(fa(cor(violent, use="pairwise.complete.obs"),1,rotate=rotation_choice))
fa.diagram(fa(cor(violent, use="pairwise.complete.obs"),1,rotate=rotation_choice))
loadings(fa(cor(violent, use="pairwise.complete.obs"),2,rotate=rotation_choice))
fa.diagram(fa(cor(violent, use="pairwise.complete.obs"),2,rotate=rotation_choice))
```

Next, we calculated our ordinal alpha measure separately in each country in order to test whether the construct is reliable in each country.

```{r violence-country}
temp <- sapply(split(pew, pew$country),
               function(x) {
                 violence <- cbind(death_apostasy=as.numeric(x$death_apostasy),
                                   severe_corporal=as.numeric(x$severe_corporal),
                                   stone_adultery=as.numeric(x$stone_adultery))
                 as.numeric(psych::alpha(polychoric(violence)$rho)$total["std.alpha"])
               })
temp <- enframe(sort(temp),"country","alpha")
ggplot(temp, aes(x=reorder(country, alpha, mean), y=alpha))+
  geom_lollipop()+
  geom_hline(yintercept = 0.7, linetype=2)+
  coord_flip()+
  labs(x=NULL, y="ordinal alpha",
       title="Ordinal alpha of violence measure by country")+
  theme_bw()
```

The results here indicate that the construct passes the tests for good reliability (>0.7) in almost all countries. The results for Egypt and Jordan were a little below this level but had alpha>0.6 in both cases. 

We next apply multigroup item response theory. Specifically we apply the standard 2PL IRT model. We first estimate a model that allows slopes and intercepts to vary freely. We then compare this to a model that force slopes to be invariant, and then to a model that forces slopes and intercepts to be invariant. These two models are functionally the same as testing metric and scalar invariance in MGCFA. We compare these models using the BIC statistic rather than chi-squared tests because on samples this large across so many countries, chi-squared tests will pick up even very small, but meaningless, deviations from invariance.


```{r irt-violence2}
violent <- na.omit(data.frame(death_apostasy=as.numeric(pew$death_apostasy),
                              severe_corporal=as.numeric(pew$severe_corporal),
                              stone_adultery=as.numeric(pew$stone_adultery),
                              country=pew$country))
mod_configural <- multipleGroup(violent[,1:3], 1, group = violent$country,
                                itemtype="2PL", verbose=FALSE)
mod_metric <- multipleGroup(violent[,1:3], 1, group = violent$country, 
                            invariance=c('slopes'),
                            itemtype="2PL", verbose=FALSE)
mod_scalar <- multipleGroup(violent[,1:3], 1, group = violent$country, 
                            invariance=c('slopes','intercepts'),
                            itemtype="2PL", verbose=FALSE)
bic <- sapply(list(mod_configural,mod_metric,mod_scalar), 
              function(x) {x@Fit$BIC})
names(bic) <- c("free","metric","scalar")
bic
```

The preferred model is the one that allows slopes and intercepts to vary freely, suggesting some degree of metric and scalar invariance. The results do suggest that the preference for the free model rather than the metric model is relatively small.

We address the issue of metric invariance fist. To investigate this issue more closely, we analyzed the results of the fully free model more closely and discovered that two countries, Egypt and Jordan, had significantly different results for the death for apostasy variable. The issue can be seen below in the correlograms for each country:

```{r}
x <- subset(pew, country=="Egypt")
violent <- cbind(death_apostasy=as.numeric(x$death_apostasy),
                 severe_corporal=as.numeric(x$severe_corporal),
                 stone_adultery=as.numeric(x$stone_adultery))
corrgram(violent, upper.panel="panel.cor", main="Egypt")
x <- subset(pew, country=="Jordan")
violent <- cbind(death_apostasy=as.numeric(x$death_apostasy),
                 severe_corporal=as.numeric(x$severe_corporal),
                 stone_adultery=as.numeric(x$stone_adultery))
corrgram(violent, upper.panel="panel.cor", main="Jordan")
```

In both cases, death for apostasy is only weakly correlated with the other two measures. Notably, in both of these countries the percentage of people who supported death for apostasy is *higher* than support for the other two items. This is in sharp contrast to all other countries where overall support for death for apostasy was the lowest of the three. This suggests greater universalism in support for death for apostasy in Jordan and Egypt which weakens the underlying construct somewhat.

To test out the effect of these countries on the metric invariance, we tested the same IRT models by excluding those countries.

```{r irt-violence}
violent_full <- na.omit(data.frame(death_apostasy=as.numeric(pew$death_apostasy),
                                   severe_corporal=as.numeric(pew$severe_corporal),
                                   stone_adultery=as.numeric(pew$stone_adultery),
                                   country=pew$country))
violent <- subset(violent_full, country!="Jordan")
mod_configural <- multipleGroup(violent[,1:3], 1, group = violent$country,
                                itemtype="2PL", verbose=FALSE)
mod_metric <- multipleGroup(violent[,1:3], 1, group = violent$country, 
                            invariance=c('slopes'),
                            itemtype="2PL", verbose=FALSE)
mod_scalar <- multipleGroup(violent[,1:3], 1, group = violent$country, 
                            invariance=c('slopes','intercepts'),
                            itemtype="2PL", verbose=FALSE)
bic_nojordan <- sapply(list(mod_configural,mod_metric,mod_scalar), 
              function(x) {x@Fit$BIC})
violent <- subset(violent_full, country!="Egypt")
mod_configural <- multipleGroup(violent[,1:3], 1, group = violent$country,
                                itemtype="2PL", verbose=FALSE)
mod_metric <- multipleGroup(violent[,1:3], 1, group = violent$country, 
                            invariance=c('slopes'),
                            itemtype="2PL", verbose=FALSE)
mod_scalar <- multipleGroup(violent[,1:3], 1, group = violent$country, 
                            invariance=c('slopes','intercepts'),
                            itemtype="2PL", verbose=FALSE)
bic_noegypt <- sapply(list(mod_configural,mod_metric,mod_scalar), 
              function(x) {x@Fit$BIC})
violent <- subset(violent_full, country!="Egypt" & country!="Jordan")
mod_configural <- multipleGroup(violent[,1:3], 1, group = violent$country,
                                itemtype="2PL", verbose=FALSE)
mod_metric <- multipleGroup(violent[,1:3], 1, group = violent$country, 
                            invariance=c('slopes'),
                            itemtype="2PL", verbose=FALSE)
mod_scalar <- multipleGroup(violent[,1:3], 1, group = violent$country, 
                            invariance=c('slopes','intercepts'),
                            itemtype="2PL", verbose=FALSE)
bic_both <- sapply(list(mod_configural,mod_metric,mod_scalar), 
                   function(x) {x@Fit$BIC})
cbind("full_sample"=bic, "w/o Jordan"=bic_nojordan, "w/o Egypt"=bic_noegypt,
      "w/o Jordan and Egypt"=bic_both)
```

The results here show clearly that removing either Jordan or Egypt is sufficient to make BIC prefer the model assuming metric equivalence. One solution to this problem would be to remove Jordan and Egypt entirely from our analysis. However, scholars have noted invariance does not necessarily invalidate the functional equivalence of items. In this case, the issue seems to be a somewhat different way that one of the items in the construct works suggesting we may have partial equivalence. I think the best way to handle this is to leave the cases in, but to note that our models may not estimate coefficients in as comparable a way for Egypt and Jordan as the other cases, and so care should be taken when interpreting those results.

The bigger problem here is the lack of scalar equivalence. The size of the difference in BIC here does not suggest that this will be fixed by identifying a handful of problematic countries. However, it is also not clear how much this should be corrected in the context of multilevel models but rather treated as an important part of cross-national differences. The argument goes that lack of scalar invariance *may* make comparison of levels (in our case random intercepts) across countries problematic. However, its also clear that in many cases it will not, as the substantive impacts of this difference may be quite small. 

I think the best way to handle this is to conduct a sensitivity analysis where we model each of the items in a separate multilevel logit model. We can then compare model output (fixed effect coefficients and the correlation between random components) to ensure that each of these models comes to largely the same conclusions. That will give much more weight to our decision to use a summated scale. 

## Religiosity 
<a href="#top">Back to top</a>

This is a classic measure in studies of religion in the Western context, but is often used as a multi-dimensional construct measuring a variety of different concepts. We are using it as a measure of the intensity of religious belief and practice in a person's life, separate from specific kinds of practices, rituals, and beliefs. We are considering the four variables below. 

+------------------------+--------------------------------------+---------------------------+
| Name                   | Question                             | Missing Countries         |
+========================+======================================+===========================+
| attend  (Q34)          | Frequency of mosque attendance       |                           |
+------------------------+--------------------------------------+---------------------------+
| relig_important (Q36)  | How important is religion in life?   |                           |
+------------------------+--------------------------------------+---------------------------+
| prayer (Q61)           | How often do you pray?               |                           |
+------------------------+--------------------------------------+---------------------------+

We also have question on the importance of the Koran and whether the repsondent triees to "follow the prophet" but these questions were not asked in the African sample. I am also a little concerned about the attendance variable. It is a common component of religiosity measures in the west but mosque attendance is not as regularized in Islam as church attendance is in Christianity. Furthermore, mosque attendance prescriptions are different for men and women.

```{r religiosity}
religiosity <- cbind(attend=as.numeric(pew$attend), 
                     relig_important=as.numeric(pew$relig_important),
                     prayer=as.numeric(pew$prayer))
corrgram(religiosity, upper.panel="panel.cor", order="PCA")

cor_relig <- polychoric(religiosity, global=FALSE)$rho

psych::alpha(cor_relig)

loadings(fa(cor_relig,1,rotate=rotation_choice))
fa.diagram(fa(cor_relig,1,rotate=rotation_choice))

loadings(fa(cor_relig,2,rotate=rotation_choice))
fa.diagram(fa(cor_relig,2,rotate=rotation_choice))
```

So over the whole sample the religiosity items seems to hold up well as a single factor. Lets check on the gender issue with attendance:

```{r}
#check on gender issue with attendance
100*round(prop.table(table(pew$attend, pew$gender),2),3)
```

We can clearly see the differential effects for men and women. Women had overall much lower attendance than men, but that is built into cultural practices and should not be considered an intrinsic part of religiosity.

Next we look at the alpha level of this construct across each country.

```{r religiosity-country}
temp <- sapply(split(pew, pew$country),
       function(x) {
         religiosity <- cbind(attend=as.numeric(x$attend), 
                              relig_important=as.numeric(x$relig_important),
                              prayer=as.numeric(x$prayer))
         as.numeric(psych::alpha(polychoric(religiosity, correct=.1, global=FALSE)$rho)$total["std.alpha"])
       })
temp <- enframe(sort(temp),"country","alpha")
ggplot(temp, aes(x=reorder(country, alpha, mean), y=alpha))+
  geom_lollipop()+
  geom_hline(yintercept = 0.7, linetype=2)+
  coord_flip()+
  labs(x=NULL, y="ordinal alpha",
       title="Ordinal alpha of religiosity measure by country")+
  theme_bw()
```

The results here are not great. While the construct is reliable in some countries, we are seeing somewhere around a third of countries with reliability well below any standard rule of thumb. 

Based on the lack of reliability across countries and the issue with gender for the attendance variable, I think the best approach here would be to include each measure of religiosity separately into the models.


## Theological Conservatism
<a href="#top">Back to top</a>

Theological conservatism is a common characteristic in studies of religion in the West. Olson and Carroll have created a composite variable from the GSS data in the US. Theological conservatism measures the importance of literalism and orthodoxy in religious belief. These are the candidate variables that we are considering as part of theological conservatism. 

+------------------------+---------------------------------------+---------------------------+
| Name                   | Question                              | Missing Countries         |
+========================+=======================================+===========================+
| believe_moral (Q16)    |Necessary to believe in god to be moral| - Afghanistan             |
+------------------------+---------------------------------------+---------------------------+
| islam_truth (Q55)      |Islam is the one true faith            | - Afghanistan             |
|                        |                                       | - Iran                    |
+------------------------+---------------------------------------+---------------------------+
| islam_oneway (Q57)     |One way to interpret religious teaching| - Iran                    |
+------------------------+---------------------------------------+---------------------------+


```{r theocons}
theocons <- cbind(believe_moral=as.numeric(pew$believe_moral),
                  islam_truth=as.numeric(pew$islam_truth), 
                  islam_oneway=as.numeric(pew$islam_oneway))
corrgram(theocons, upper.panel="panel.cor", order="PCA")

cor_theocons <- polychoric(theocons)$rho

psych::alpha(cor_theocons)

loadings(fa(cor_theocons,1,rotate=rotation_choice))
fa.diagram(fa(cor_theocons,1,rotate=rotation_choice))
loadings(fa(cor_theocons,2,rotate=rotation_choice))
fa.diagram(fa(cor_theocons,2,rotate=rotation_choice))
```

The results here are not great. Its clear that the believe_moral variable does not really belong in the same construct. I could still consider the two variables on one way and truth of Islam, but the data reduction value here does not seem to justify the combination of these variables. I think the sensible solution is to include them separately in the model.

## Social conservatism
<a href="#top">Back to top</a>

Social conservatism all relate to Q84. Respondents were asked whether the following behaviors were morally acceptable, morally wrong, or not a moral issue. 

- Divorce
- Polygamy (left out because it correlates with nothing else)
- Limiting the number of children (Not asked in Iran or Sub-Saharan Africa)
- Drinking Alcohol
- Euthanasia
- Suicide
- Abortion
- Prostitution (not asked in Afghanistan and Iran)
- Sex between people who are not married to each other (not asked in Afghanistan and Iran)
- Homosexual behavior (not asked in Afghanistan and Iran)

This question was not asked at all in Morocco and Uzbekistan.

Many of the responses may indirectly relate to religious beliefs but they do not specifically ask about a connection to religious belief. Thus this gives us a way to separate religiosity and theological conservatism from general social conservatism in the models. 

```{r morality}
morality <- cbind(moral_divorce=as.numeric(pew$moral_divorce),
                  moral_fertility=as.numeric(pew$moral_fertility),
                  moral_alcohol=as.numeric(pew$moral_alcohol),
                  moral_euthansia=as.numeric(pew$moral_euthanasia),
                  moral_suicide=as.numeric(pew$moral_suicide),
                  moral_abortion=as.numeric(pew$moral_abortion),
                  moral_prostitution=as.numeric(pew$moral_prostitution),
                  moral_premar_sex=as.numeric(pew$moral_premar_sex),
                  moral_gay=as.numeric(pew$moral_gay))
corrgram(morality, upper.panel="panel.cor", order="PCA")
```

The initial correlogram clearly suggests that the fertility and divorce measure do not relate much to the remaining items and so I drop them from the analysis.

```{r}
cor_morality <- polychoric(morality[,-1*1:2])$rho

psych::alpha(cor_morality)
```

The alpha is strong here and suggests that dropping any of the remaining items would not improve reliability. Lets investigate factor loadings in a couple of different models.

```{r}
vss(cor_morality)

loadings(fa(cor_morality,1,rotate=rotation_choice))
loadings(fa(cor_morality,2,rotate=rotation_choice))
loadings(fa(cor_morality,3,rotate=rotation_choice))

#lets diagram two vs three factor solutions
fa.diagram(fa(cor_morality,1,rotate=rotation_choice))
fa.diagram(fa(cor_morality,2,rotate=rotation_choice))
fa.diagram(fa(cor_morality,3,rotate=rotation_choice))
```

Its possible that some more complex model structure would be preferred here, namely one that separates the questions about "death stuff" (suicide, euthansia, and abortion) from everything else. Nonetheless a single factor model also works pretty well and meets my goals of data reduction on this variable.

Lets look at reliability of this measure across countries.

```{r morality-country}
temp <- sapply(split(pew, pew$country),
       function(x) {
         morality <- cbind(moral_alcohol=as.numeric(x$moral_alcohol),
                           moral_euthansia=as.numeric(x$moral_euthanasia),
                           moral_suicide=as.numeric(x$moral_suicide),
                           moral_abortion=as.numeric(x$moral_abortion),
                           moral_prostitution=as.numeric(x$moral_prostitution),
                           moral_premar_sex=as.numeric(x$moral_premar_sex),
                           moral_gay=as.numeric(x$moral_gay))
         as.numeric(psych::alpha(polychoric(morality)$rho)$total["std.alpha"])
       })
temp <- enframe(sort(temp),"country","alpha")
ggplot(temp, aes(x=reorder(country, alpha, mean), y=alpha))+
  geom_lollipop()+
  geom_hline(yintercept = 0.7, linetype=2)+
  coord_flip()+
  labs(x=NULL, y="ordinal alpha",
       title="Ordinal alpha of morality measure by country")+
  theme_bw()
```

The results look good here. Only Egypt falls below the 0.7 threshold, but not by much. 

I next analyzed measurement invariance. The IRT models for polytomous outcomes failed to run, because for some countries there were zero respondents in the morally acceptable column. Most of the variation is between the group that said "morally wrong" and those that said anything else. So, I collapsed the results into this binary outcome and then ran IRT models using a 2PL structure.

```{r}
morality <- na.omit(data.frame(moral_alcohol=as.numeric(pew$moral_alcohol=="Morally wrong"),
                               moral_euthansia=as.numeric(pew$moral_euthanasia=="Morally wrong"),
                               moral_suicide=as.numeric(pew$moral_suicide=="Morally wrong"),
                               moral_abortion=as.numeric(pew$moral_abortion=="Morally wrong"),
                               moral_prostitution=as.numeric(pew$moral_prostitution=="Morally wrong"),
                               moral_premar_sex=as.numeric(pew$moral_premar_sex=="Morally wrong"),
                               moral_gay=as.numeric(pew$moral_gay=="Morally wrong"),
                               country=as.character(pew$country)))
mod_configural <- multipleGroup(morality[,1:7], 1, group = morality$country,
                                itemtype="2PL", verbose=FALSE)
mod_metric <- multipleGroup(morality[,1:7], 1, group = morality$country, 
                            invariance=c('slopes'),
                            itemtype="2PL", verbose=FALSE)
mod_scalar <- multipleGroup(morality[,1:7], 1, group = morality$country, 
                            invariance=c('slopes','intercepts'),
                            itemtype="2PL", verbose=FALSE)
bic <- sapply(list(mod_configural,mod_metric,mod_scalar), 
              function(x) {x@Fit$BIC})
names(bic) <- c("free","metric","scalar")
bic
```

The results here suggest some important invariance. The results by country suggested that (a) the effect of alcohol was substantially variant across countries and (b) the results might work better in a two factor model that separated the remaining "death" items (euthansia, suicide, and abortion) from the "sex" items (prostitutions, premarital sex, and homosexuality). Thus, we tried another IRT that left out alcohol, and fit a two factor solution.


```{r}
morality <- na.omit(data.frame(moral_euthansia=as.numeric(pew$moral_euthanasia=="Morally wrong"),
                               moral_suicide=as.numeric(pew$moral_suicide=="Morally wrong"),
                               moral_abortion=as.numeric(pew$moral_abortion=="Morally wrong"),
                               moral_prostitution=as.numeric(pew$moral_prostitution=="Morally wrong"),
                               moral_premar_sex=as.numeric(pew$moral_premar_sex=="Morally wrong"),
                               moral_gay=as.numeric(pew$moral_gay=="Morally wrong"),
                               country=as.character(pew$country)))
mod_configural <- multipleGroup(morality[,1:6], 2, group = morality$country,
                                itemtype="2PL", verbose=FALSE)
mod_metric <- multipleGroup(morality[,1:6], 2, group = morality$country, 
                            invariance=c('slopes'),
                            itemtype="2PL", verbose=FALSE)
mod_scalar <- multipleGroup(morality[,1:6], 2, group = morality$country, 
                            invariance=c('slopes','intercepts'),
                            itemtype="2PL", verbose=FALSE)
bic <- sapply(list(mod_configural,mod_metric,mod_scalar), 
              function(x) {x@Fit$BIC})
names(bic) <- c("free","metric","scalar")
bic
```

The results here suggest metric invariance. We still do not achieve scalar invariance. Given that the major goal here is to just reduce the complexity of the data and that scalar invariance is very difficult to obtain, I am ok with that.


